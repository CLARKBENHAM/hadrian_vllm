Using a vLLM to solve Hadrian's Conversions Issues
Take CAD Model of ideal shape, Blueprint with tolerances, return unified standard.

# Standards
semantic PMI for machine, graphic PMI for humans


# Data Sources
NIST - 12 labeled assembly and part examples
  https://docs.google.com/spreadsheets/d/1tdtUZaJAdkri25PN4LroGV-EJTjW0Uh98TclfjHdJlk/edit?gid=462465708#gid=462465708 where it's all munged together, use "data/fsi_labels/Hadrian\ Vllm\ test\ case\ -\ Final\ Merge.csv" and fsi labeled parts
		asem6 DT3 duplicated pg3
More advanced AP242 case http://www.asd-ssg.org/step-ap242-benchmark.html
Forum for checking cad integrations: https://www.mbx-if.org/home/cax/

Can't use STEP file analyzer and view since on mac

Synthetic Data:
	get CAD model, create 2d plans from render, add a bunch of notation see if can map back to part?
		How to annotate each part on blueprint via cad?

# Competitors
Automates measurment routines from (most Similar)
	https://blog.manufacturing.hexagon.com/integrate-2d-blueprints-to-3d-cad-models-at-the-click-of-a-button-in-pc-dmis/ (2019)
Create 2d Drawings for inspection from CAD
	https://www.babtec.com/products/cad-integration?utm_source=chatgpt.com
	"GD&T Selection from File"
Multiple people do analysis once part is made with tolerances
	uses cad from the start: https://www.3dcs.com/tolerance-analysis-software-and-spc-systems/3dcs-software/catia-v5-integrated?utm_source=chatgpt.com
	https://www.sigmetrix.com/software/cetol
Create CNC plan from 3D model
	adjusts tolerances to fit part https://camworks.com/tolerance-based-machining/?utm_source=chatgpt.com


# Which vLLM
Try Azure for 4o

Itar complient:
	Try Sonnet 3.5, 4o.
	Don't go to self-hosting yet.
Without ITAR it'd be:
	google gemini-2.0 (only via api not console unless advanced user)

ITAR compliant:
	aws has GovCloud and any US-WEST  `AWS GovCloud (US-West)` qualifies
		sonnet 3.5, Haiku 3.5, Llama 3 70B Instruct,
		https://docs.aws.amazon.com/govcloud-us/latest/UserGuide/govcloud-bedrock.html
		Can finetune haiku 3.5; not sonnet. Unclear if allowed while ITAR compliant
	Azure Gov
		can use 4o via "FedRAMP High Authorization for Azure Government"  https://devblogs.microsoft.com/azuregov/azure-openai-fedramp-high-for-government/?utm_source=chatgpt.com
			unclear if can finetune
		but none of o-class model yet https://learn.microsoft.com/en-us/azure/ai-services/openai/azure-government
	Google "Assured Workflows"
		ITAR services https://cloud.google.com/assured-workloads/docs/itar-restrictions-limitations
			doesn't seem to include an models?
		Requires an org to start using: https://console.cloud.google.com/projectselector2/compliance/assuredworkloads?hl=en&pli=1&supportedpurview=organizationId&orgonly=true




### Data Sources - Adjusting definitions for transcription
Solved
# parallelism not matching symbol render


#Using | to deliniate boxes isn't stanardized?
# "All Around" added but no description on page? T23
# "Datum Feature" # asem8 DF1, added to modifiers
# LDN1, RLE1, CH1, how's that supposed to be transcribed? No text on diagram, just must infer
# single position symbol
# D2 using / for 1 value over another as fraction on page
# Profile surface label to right of page, T28:
# CS1
# the big circles, VSI


### Inital Model Quality
	Think I gotta finetune

	Gemini is basically getting it aside from unicode specific chars, particularly what differs from spec and answer sheet
		4o struggles with correct unicode
	Does all right with enumerating all element within a confined screenshot of about 6, though keeps thinking âˆ  is used when it isn't.
		Would make about 3 GD&T symbol mistakes
	O3 on full page screenshots:
		Only got what was in a closeup. Then T13 didn't include the 2nd row, D15 had digits transposed, T14 was totally off. and the top half was totally skiped.

	split screenshots and send works w 4o if the elements are level with page (assem 6) and at least 10 at a time. Have to keep reminding to use symbols and rules
		if off kilter to page (assem 7), 3 elem reminded twice, 7 elem needed o3-mini twice. But it also broke on a specific element asem7 t2.
		Send full screenshot, and got total halucinates twice, even when said first was a total halucination.
	So splitscreen q with few shot can get if use Best-of-N. Maybe also aggregate post-hoc with o3 mini?
		https://chatgpt.com/c/67b7c08e-38cc-8004-a967-da5c70589124 4o not quite, o3-mini mostly
		https://aistudio.google.com/prompts/1Pxgv5wu66P6C_7_LccWGPhsMXklx3vVA not as good w/o few shot
	Full screenshot 1 element id fails utterly. Not a problem with image resizing.
		o3-mini failing but O1 succedds on img with 8 total:
		and gemini-pro-2.0 (mostly) O1 (mostly), succeed on 17 example also
			https://chatgpt.com/c/67b7cef7-9740-8004-a3aa-24a39e4b8f10
			https://aistudio.google.com/prompts/1AMb4FUSThR9LgS65zcoZFi41QHY-J2LY
	Part of it might be full rules, versus just getting the symbols out. Though there is often a problem identifying which exact GD&T symbol.
	Pass GD&T symbols with their names does slightly better than if its the raw symbols?

#### Element IDs
For Sending in single pages screenshots:
O1's Hallucinated IDs: 10% vs Gemini at 22%.
O1 failed to include 8.3% of element ids, Gemini missed 7.6%
O1 had the wrong page 9.3%, and Gemini had the wrong page 2.3%.
While I only checked where the models disagreed, the runs of numbers made sense, so Gemini likely better here.
Gemini got Asembly 11 perect, when returning 20ish element ids it fails.

If it can't even get element IDs from the full diagram, individual pages will be hard. Might have to use OCR directly to get text out and then combine for logic?

Spliting single page screenshot into quarters to see improvement.
Gemini-2.0-Pro got first page element ids all correct by quarters.

gemini-2.0-flash-001
Gemini Hallucination rate: ~11%
Gemini Missed rate: 2.78%
Gemini Disagreement rate: 0%, except for 2 where multiple pages were returned
gpt-4o Hallucination rate: 10.1%
gpt-4o Missed rate: 5.83%
gpt-4o Disagreement rate: 0%,  except for 4 where multiple pages were returned
o1 Hallucination rate: 13.1%
o1 Missed rate: 5.00%
o1 Disagreement rate: 0%,  except for 4 where multiple pages were returned




